---
output: github_document
# date: "2022-10-17"
---

# abnoRmal
##### an analysis of The Strokes' discography using the `spotifyr` package and my Spotify listening history

![](strokes_reptilia_narrow.png)

___

```{r setup, message = F, warning = F, include = F}
library(tidyverse)
library(spotifyr)
library(DT)
library(ggridges)

# library(spotifyr)
# library(plyr)
# library(tidyverse)
# library(httr)
# library(rvest)
# library(stringr)
# library(ggthemes)
# library(tidytext)
# library(wordcloud)
# library(ggridges)
# library(wesanderson)
# library(yarrr)
# library(knitr)
# library(kableExtra)
# library(radarchart)

options(scipen = 999)
knitr::opts_chunk$set(message = F, warning = F)
theme_set(theme_minimal())
```

```{r API link, include = F}
# setting up my Spotify client ID & client secret
Sys.setenv(SPOTIFY_CLIENT_ID = "5d531eb87ca340cb8e8e1faad7bed4fa")
Sys.setenv(SPOTIFY_CLIENT_SECRET = "1f4c4a6c46524ed391414a94dbe5bc4b")
access_token = get_spotify_access_token()
```

```{r API link to publish, eval = F, include = T}
# setting up my Spotify client ID & client secret
Sys.setenv(SPOTIFY_CLIENT_ID = "client ID here")
Sys.setenv(SPOTIFY_CLIENT_SECRET = "client secret here")
access_token = get_spotify_access_token()
```

```{r}
# using spotifyr to get data on The Strokes
strokes = get_artist_audio_features("the strokes")

# confirming we have the correct albums
strokes |>
  count(album_name)
```

There are too many tracks for *Is This It* and *First Impressions Of Earth* - let's inspect that (although I wish they had 33 and 28 tracks)

```{r}
strokes |>
  filter(album_name == "First Impressions Of Earth") |>
  count(track_name) |>
  head(5)
```

looks like everything is double counted, there seems to just be one duplicate - let's inspect what's different by looking at the multiple entries for the album's first track, *You Only Live Once*

```{r}
strokes |>
  filter(track_name == "You Only Live Once") |>
  select(artist_name, album_release_date, track_name, album_name)
```

we have different values for the following variables:

- `danceability` (0.631 v. 0.630)
- `energy` (0.905 v. 0.908)
- `loudness` (-2.44 v. -2.42)
- `speechiness` (0.0325 v. 0.0326)
- `acousticness` (0.0328 v. 0.0238)
- `instrumentalness` (0.528 v. 0.592)
- `liveness` (0.125 v. 0.116)
- `valence` (0.969 v. 0.968)
- `tempo` (120.520 v. 120.522)

so how do we decide which one we keep and which we omit?

looking at [this forum](https://community.spotify.com/t5/iOS-iPhone-iPad/Duplicates-of-the-same-albums/td-p/4542505), it looks like i would probably want to default to the most recent release. however, as you can see below, the different versions of the album in the data have the same release date.

```{r}
strokes |>
  filter(album_name == "First Impressions Of Earth") |>
  count(album_release_date)
```

upon further inspection, i found my answer in the `album_images` column. i'll put the images side-by-side below and we can pretty easily see which one is the right album cover.

![](fioe side by side.png)

so now i'll make sure to omit all instances of the first version of the album using the `album_id` variable, which is unique for each of the two versions.

```{r}
strokes = strokes |>
  filter(album_id != "1HQ61my1h3VWp2EBWKlp0n")
```

and now we need to address the same issue for The Strokes' first album, *Is This It*.

```{r}
strokes |>
  filter(album_name == "Is This It") |>
  count(track_name) |>
  head(5)
```

here we have three different versions of the album. again, taking a look at the album images, i can tell which one is the version currently on spotify, so i will choose that one to keep.

```{r}
strokes = strokes |>
  filter(album_id != "1BbxngE1wn7Lzantkvket2" & album_id != "2yNaksHgeMQM9Quse463b5")

strokes |>
  count(album_name)
```

now the data is free of duplicates and we can resume with our analysis.

```{r}
strokes |>
  select(artist_name, album_name, track_name) |>
  head(9)
```

```{r}
# genius_get_artists <- function(artist_name = "the strokes", n_results = 10) {
#   baseURL <- 'https://api.genius.com/search?q='
#   requestURL <- paste0(baseURL, gsub(' ', '%20', artist_name),
#                        '&per_page=', n_results,
#                        '&access_token=', access_token)
#   
#   res <- GET(requestURL) %>% content %>% .$response %>% .$hits
#   
#   map_df(1:length(res), function(x) {
#     tmp <- res[[x]]$result$primary_artist
#     list(
#       artist_id = tmp$id,
#       artist_name = tmp$name
#     )
#   }) %>% unique
# }
# 
# genius_artists = genius_get_artists("the strokes")
```

```{r}
# names(strokes)[9:19]
album_levels = c("Is This It", "Room On Fire", "First Impressions Of Earth",
                 "Angles", "Comedown Machine", "The New Abnormal")

strokes$album_name = factor(strokes$album_name, levels = album_levels)

strokes |>
  ggplot(aes(valence, fct_rev(album_name))) +
  geom_density_ridges(aes(fill = album_name), scale = 0.9, col = "transparent", alpha = 0.75) +
  labs(x = "valence", y = NULL) +
  theme(legend.position = "none",
        axis.text.x = element_blank())
```

```{r}
# library(geniusr)
# genius_token(T)
# client id = u2X4arrcpERbK2qUOuWi4-SNWDNUJ8bMinDq6jbQPFWKFthB-g5mHNOZjer1Hk7z
# client secret = kOLR9vdB1UsVAOT8gttk2EyeMULG71AL4tVuGQlSpvIiy0YNYo8J_NwZerYm-0FATalY4ydA7SRJnTzHS4zfBA
# access token = q2nsw8oL2l8J5Qs6-Y2DbczMuEUBVgyZ5GetLPuDdxbia3kP78xssEwKSt4GXif0
```

```{r}
# library(geniusr)
# library(dplyr)
# library(tidytext)

# get lyrics
# get_lyrics_search(artist_name = "Kanye West",
#                   song_title = "Good Morning") %>% 
#   # get lyric bigrams
#   unnest_tokens(bigram, line, token = "ngrams", n = 2) %>%
#   # look for good morning
#   filter(bigram == "good morning") %>% 
#   # count bigram frequency
#   nrow()

# songs_df = data.frame(song = c("Soma", "Is This It"), lyrics = NA)
# for (i in 1:nrow(songs_df)) {
#   df1 = get_lyrics_search(artist_name = "The Strokes", song_title = songs_df$song[1])
#   str = ""
#   for (i in 1:nrow(df1)) { str = paste(str, df1$line[i]) }
#   lyrics = trimws(str)
#   songs_df$lyrics[i] = lyrics
#   songs_df
# }

### THE ABOVE ISN'T WORKING - MIGHT HAVE TO TRY A JOIN INSTEAD ###

# get_lyrics_search(artist_name = "The Strokes",
#                   song_title = "Soma")

# get_artist_songs(artist_id = "The Strokes")
```

```{r}
get_song_lyrics = function(song) {
  df = get_lyrics_search(artist_name = "The Strokes",
                         song_title = song)
  str = ""
  for (i in 1:nrow(df)) {
    str = paste(str, df$line[i])
  }
  return(trimws(str))
}
```

```{r}
# songs = c("Soma", "Someday")
#
# for (song in songs) {
#   print(get_song_lyrics("The Strokes", song))
# }
```

```{r}
# strokes$lyrics = "nothing yet"
```

```{r}
# num = 1
# song_name = strokes$track_name[num]
# lyrics = get_lyrics_search("The Strokes", song_name) |>
#   pull(line)
# 
# str = ""
# 
# for (i in 1:length(lyrics)) {
#   str = paste(str, lyrics[i])
# }
# 
# str = trimws(str)
# song_df = data.frame(track_name = song_name, lyrics = str)
# 
# strokes = left_join(strokes, song_df, by = "track_name")
```

```{r}
# lyrs = read_csv("all_with_lyrics.csv", col_types = cols())
# strokes = left_join(strokes, lyrs, by = "track_name")
```

```{r}
### this works, chunk below will try to do it in a loop ###
# strokes |>
#   arrange(album_release_date) |>
#   select(track_name, lyrics)
# 
# track = "50/50"
# lyr = get_song_lyrics(track)
# index = which(strokes$track_name == track)
# strokes$lyrics[index] = lyr

# strokes[which(is.na(strokes$lyrics)), ] |>
#   select(track_name, lyrics)
```

```{r}
# strokes$lyrics[which(strokes$track_name == "50/50")] = "Why's she telling me the story of her life? All the things you wanna kill will give you spite And if you've taken all the prisoners inside As they're doling out their wisdom in the fire I will say! I will say don't judge me! I will say! I will say don't judge me! I wait on a darkened highway! I wait on a darkened highway! I can take as long as without looking by Why's she telling me the story of her life And if you've taken all the prisoners inside As they've thrown all their wisdom in the fire I will say! I will say don't judge me! I will say! I will say don't judge me! I wait on a darkened highway! I wait on a darkened highway! I will say! I will say don't judge me! I will say! I will say don't judge me! I wait on a darkened highway! I wait on a darkened highway!"
# 
# strokes$lyrics[which(strokes$track_name == "12:51")] = "Talk to me now I'm older Your friend told you 'cause I told her Friday nights have been lonely Change your plans and then phone me We could go and get forties Fuck goin' to that party Oh, really, your folks are away now? Alright, let's go, you convinced me 12:51 is the time my voice Found the words I sought Is it this stage I want? The world is shutting out for us Oh, we were tense for sure But we was confident Kiss me now that I'm older I won't try to control you Friday nights have been lonely Take it slow but don't warn me We'd go out and get forties Then we'd go to some party Oh, really, your folks are away now? Alright, I'm coming I'll be right there"
```

```{r}
# strokes |>
#   count(lyrics)
```

# WE FINALLY HAVE ALL THE LYRICS

```{r}
strokes = read_csv("strokes_all_lyrics.csv", col_types = cols())
```

```{r}
library(tidytext)
library(wordcloud)
library(wesanderson)
library(dplyr)
library(yarrr)

word_count = strokes |>
  unnest_tokens(word, lyrics) |>
  count(word, sort = T) |>
  mutate(word = reorder(word, n)) |>
  ungroup()

generate_wordcloud = function(part) {
  valid_words = parts_of_speech |>
    filter(str_detect(pos, part)) |>
    pull(word)
  
  fdata = word_count |>
    filter(word %in% valid_words)
  
  wordcloud(words = fdata$word, freq = fdata$n,
            max.words = 100, random.order = F,
            colors = c("#ABCCD4", "#E9B3FF", "#82AC7E"))
}

generate_wordcloud("Noun")
generate_wordcloud("Adjective")
generate_wordcloud("Adverb")
generate_wordcloud("Verb")
```

```{r}
pirateplot(valence + danceability + energy ~ album_release_year, strokes,
           pal = c("#FFF58F", "#C10000", "#000000", "#FF7DEF", "#FF5F5A", "#5AA0FF"),
           xlab = "album", ylab = "sonic score", main = "sonic score = valence + danceability + energy",
           theme = 0, point.o = 0.7, avg.line.o = 1, jitter.val = .05, 
           bty = "n", cex.axis = 0.6, xaxt = "n")

axis(1, cex.axis = 0.6, lwd = 0)
legend("topright", c("1: Is This It", "2: Room on Fire", "3: First Impressions of Earth",
                     "4: Angles", "5: Comedown Machine", "6: The New Abnormal"), bty = "n", cex = 0.6)
```

```{r}
sonic_tracks = function(album) {
  return(strokes |>
           mutate(sonic_score = valence + danceability + energy) |>
           select(album_name, track_name, sonic_score) |>
           arrange(desc(sonic_score)) |>
           filter(album_name == album))
}

all_albums = c("Is This It", "Room On Fire", "First Impressions Of Earth",
               "Angles", "Comedown Machine", "The New Abnormal")

lapply(all_albums, sonic_tracks)
```

```{r}
words_by_album = strokes |>
  select(album_name, track_name, lyrics) |>
  unnest_tokens(words, lyrics) |>
  group_by(album_name, track_name) |>
  summarise(n = n(),
            .groups = "drop")

unique_words_album = strokes |>
  select(album_name, track_name, lyrics) |>
  unnest_tokens(words, lyrics) |>
  group_by(album_name, track_name) |>
  distinct(words) |>
  group_by(album_name, track_name) |>
  summarise(n = n(),
            .groups = "drop")

track_lex_diversity = words_by_album |>
  left_join(unique_words_album, by = c("album_name", "track_name")) |>
  rename(words = n.x, unique_words = n.y) |>
  mutate(lexical_diversity = round(unique_words / words, 3)) |>
  arrange(desc(lexical_diversity)) |>
  select(album_name, track_name, lexical_diversity)

ld_limit = 10

bind_rows(head(arrange(track_lex_diversity, desc(lexical_diversity)), ld_limit),
          tail(arrange(track_lex_diversity, desc(lexical_diversity)), ld_limit)) |>
  arrange(desc(lexical_diversity)) |>
  ggplot(aes(reorder(track_name, lexical_diversity), lexical_diversity)) +
  geom_col(aes(fill = album_name), width = 0.5, alpha = 0.75) +
  geom_text(aes(label = lexical_diversity), hjust = -0.5, size = 3) +
  geom_vline(xintercept = 10.5, linetype = "dotted") +
  coord_flip(ylim = c(0, 0.75)) +
  labs(x = "song title", y = "lexical diversity", fill = NULL,
       title = "ten most and least lexically diverse Strokes tracks") +
  theme(plot.title = element_text(hjust = 0.5))
```




























